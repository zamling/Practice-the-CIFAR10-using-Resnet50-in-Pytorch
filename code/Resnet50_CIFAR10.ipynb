{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\nfrom tqdm import tqdm\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.models as models\n\nimport matplotlib.pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nbatch_size=32\nnum_epoches=5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!tar -zxvf ../input/cifar10-python/cifar-10-python.tar.gz\nos.listdir('.')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\ntrans = transforms.Compose([transforms.RandomCrop(32, padding=4),  #先四周填充0，在吧图像随机裁剪成32*32\n    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n\ntrainset=torchvision.datasets.CIFAR10(root='.', train=True, download=False, transform=trans)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n\ntrans_test=transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\ntestset = torchvision.datasets.CIFAR10(root='.', train=False, download=False, transform=trans_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=2*batch_size, shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# image, label = trainset[0]\n# def imshow(img):\n#     img = img / 2 + 0.5     # unnormalize\n#     npimg = img.numpy()\n#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n# imshow(image)\n# print(classes[label])\n#load succefully","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"set up the general Resnet\n<br/>Note:\n1. nn.Conv2d's parameters are input's channels, output channels. Don't care the size of the image\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"class bottleneck(nn.Module):\n    def __init__(self,in_planes, planes,stride=1):\n        super(bottleneck,self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n                                stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, 4*planes,\n                               kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(4*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != 4*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, 4*planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(4*planes)\n            )\n            pass\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Resnet50(nn.Module):\n    def __init__(self):\n        super(Resnet50,self).__init__()\n        self.current_input = 64\n        self.conv1=nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1,bias=False)\n        self.BN1=nn.BatchNorm2d(64)\n        # generate the mid-layers the pattern is:\n        #(1*1[64]->3*3[64]->1*1[256])*3\n        #(1*1[128]->3*3[128]->1*1[512])*4\n        #(1*1[256]->3*3[256]->1*1[1024])*6\n        ##(1*1[512]->3*3[512]->1*1[2048])*3\n        self.layer_1=self._generate_layers(64,3,stride=1)# (inputs,number)\n        self.layer_2=self._generate_layers(128,4,stride=2)\n        self.layer_3=self._generate_layers(256,6,stride=2)\n        self.layer_4=self._generate_layers(512,3,stride=2)\n        \n        self.linear = nn.Linear(2048,10)\n        pass\n    \n    def _generate_layers(self,des_output,numbers,stride):\n        strides = [stride] + [1]*(numbers-1)\n        layers=[]\n        for stride in strides:\n            layers.append(bottleneck(self.current_input,des_output,stride))\n            self.current_input = des_output*4\n            pass\n        return nn.Sequential(*layers)\n    \n    def forward(self,x):\n        out = F.relu(self.BN1(self.conv1(x)))\n        out = self.layer_1(out)\n        out = self.layer_2(out)\n        out = self.layer_3(out)\n        out = self.layer_4(out)\n        out = F.avg_pool2d(out,4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n    \n    \nnet=Resnet50()\n    \n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\nlosses=[]\nfor epoch in range(1):  # loop over the dataset multiple times\n    running_loss = 0.0\n    pbar = tqdm(trainloader)\n    i = 0\n\n    for data in pbar:\n        # get the inputs\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n            \n        if i%100==0:\n            losses.append(loss.data.numpy())\n            print(losses)\n            pass\n\n        pbar.set_description(\"Processing epoch {:d} minibatch {:d} train loss {:.3f}\".format(epoch,\\\n                                                                i+1, running_loss/(i+1)))\n        i += 1      \nprint(losses)\n\nprint('Finished Training')\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(np.arange(len(losses)),losses)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    correct = 0\n    total = 0\n    for i,data in enumerate(testloader, 0):\n        net.eval()\n        img,labels = data\n        outputs=net(img)\n        _,predicted = torch.max(outputs.data,1)\n        total += labels.size(0)\n        correct += (predicted==labels).sum()\n        if (i+1)%10==0:\n             print(\"the correct is %.3f%%\"%(100*correct/total))\n     \n            \n   ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}